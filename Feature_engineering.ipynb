{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd368974",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3252ff97-19b6-4833-b119-bdb5b36a545b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-15T17:47:10.725895Z",
     "start_time": "2023-04-15T17:47:10.463976Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 23:07:38.765749: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-10 23:07:39.338977: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score,roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from joblib import Parallel, delayed\n",
    "import joblib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "915bd733",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb30ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assignment_rel=pd.read_csv('./data/assignment_relationships.csv')\n",
    "df_training=pd.read_csv('./data/training_unit_test_scores.csv')\n",
    "df_eval=pd.read_csv('./data/evaluation_unit_test_scores.csv')\n",
    "df_actionlogs=pd.read_csv('./data/files/action_logs.csv')\n",
    "df_assignment=pd.read_csv('./data/assignment_details.csv')\n",
    "df_sequence=pd.read_csv('./data/sequence_details.csv')\n",
    "df_problem=pd.read_csv('./data/problem_details.csv')\n",
    "df_total=pd.read_csv('./data/unit_test_scores.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f67073d",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43f957a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine train and evaluation data to get features\n",
    "df_final=pd.concat([df_training,df_eval[['assignment_log_id', 'problem_id', 'score']]])\n",
    "# get related in-unit assignment log ids using assignment relationships\n",
    "df_final=df_final.merge(df_assignment_rel,left_on='assignment_log_id',right_on='unit_test_assignment_log_id',how='left')\n",
    "#filter required features\n",
    "df_final=df_final[['unit_test_assignment_log_id','problem_id', 'score', 'in_unit_assignment_log_id']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03e65628",
   "metadata": {},
   "source": [
    "## Actionlog features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1469d2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we want to take mode(the most repeated value) for these 3 columns\n",
    "def get_max_value_counts(df, group_cols, count_col):\n",
    "    counts = df.groupby(group_cols)[count_col].value_counts()\n",
    "    max_indices = counts.groupby(group_cols).idxmax().reset_index(name=count_col)\n",
    "    max_indices[count_col] = max_indices[count_col].str[2]\n",
    "    return max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "603dd7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_action_logs(df_actionlogs, df_final):\n",
    "    df_actionlogs['max_attempts']=df_actionlogs.groupby('problem_id').max_attempts.transform('first')\n",
    "    df_actionlogs['available_core_tutoring']=df_actionlogs.groupby('problem_id').available_core_tutoring.transform('first')\n",
    "    df_actionlogs['score_viewable']=df_actionlogs.groupby('problem_id').score_viewable.transform('first')\n",
    "    df_actionlogs['continuous_score_viewable']=df_actionlogs.groupby('problem_id').continuous_score_viewable.transform('first')\n",
    "    # Fill null values with -1\n",
    "    df_actionlogs['max_attempts'] = df_actionlogs['max_attempts'].fillna(-1)\n",
    "    df_actionlogs['score_viewable'] = df_actionlogs['score_viewable'].fillna(-1)\n",
    "    df_actionlogs['continuous_score_viewable'] = df_actionlogs['continuous_score_viewable'].fillna(-1)\n",
    "    \n",
    "    # Get one-hot encoding for 'action' and 'available_core_tutoring' features\n",
    "    one_hot = pd.get_dummies(df_actionlogs[['action', 'available_core_tutoring']])\n",
    "    \n",
    "    # Concatenate the original DataFrame with the one-hot encoded DataFrame\n",
    "    df_actionlogs = pd.concat([df_actionlogs, one_hot], axis=1)\n",
    "    \n",
    "    # Drop unimportant features\n",
    "    df_actionlogs = df_actionlogs.drop(columns=['timestamp', 'problem_id', 'available_core_tutoring', 'action', 'hint_id', 'explanation_id'])\n",
    "    \n",
    "    # Merge action_logs with training data\n",
    "    df_final = df_final.merge(df_actionlogs, left_on='in_unit_assignment_log_id', right_on='assignment_log_id', how='left')\n",
    "    \n",
    "    # Group the data for each combination of 'unit_test_assignment_log_id', 'problem_id'\n",
    "    df_final_action = df_final.groupby(['unit_test_assignment_log_id', 'problem_id'], as_index=False).agg({\n",
    "        'action_answer_requested': 'sum', 'action_assignment_finished': 'sum',\n",
    "        'action_assignment_resumed': 'sum', 'action_assignment_started': 'sum',\n",
    "        'action_continue_selected': 'sum', 'action_correct_response': 'sum',\n",
    "        'action_explanation_requested': 'sum', 'action_hint_requested': 'sum',\n",
    "        'action_live_tutor_requested': 'sum', 'action_open_response': 'sum',\n",
    "        'action_problem_finished': 'sum', 'action_problem_started': 'sum',\n",
    "        'action_skill_related_video_requested': 'sum', 'action_wrong_response': 'sum',\n",
    "        'available_core_tutoring_answer': 'sum', 'available_core_tutoring_explanation': 'sum',\n",
    "        'available_core_tutoring_hint': 'sum', 'available_core_tutoring_no_tutoring': 'sum',\n",
    "        'score': 'first'\n",
    "    })\n",
    "    \n",
    "    # Get the mode (most repeated value) for these 3 columns\n",
    "    df_final_max = get_max_value_counts(df_final, ['unit_test_assignment_log_id', 'problem_id'], 'max_attempts')\n",
    "    df_final_scoreview = get_max_value_counts(df_final, ['unit_test_assignment_log_id', 'problem_id'], 'score_viewable')\n",
    "    df_final_conscoreview = get_max_value_counts(df_final, ['unit_test_assignment_log_id', 'problem_id'], 'continuous_score_viewable')\n",
    "    \n",
    "    # Merge the updated columns with df_final\n",
    "    df_final = pd.merge(\n",
    "        pd.merge(pd.merge(df_final_action, df_final_max, on=['unit_test_assignment_log_id', 'problem_id']),\n",
    "                 df_final_scoreview, on=['unit_test_assignment_log_id', 'problem_id']),\n",
    "        df_final_conscoreview, on=['unit_test_assignment_log_id', 'problem_id']\n",
    "    )\n",
    "    \n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18d3d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=preprocess_action_logs(df_actionlogs, df_final)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b486609",
   "metadata": {},
   "source": [
    "## Assignment Details features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7e7812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_assignment_data(df_final, df_assignment, df_assignment_rel):\n",
    "    # Assign a column indicating unfinished assignments\n",
    "    df_assignment[\"notfinish\"] = df_assignment['assignment_end_time'].isnull().astype(int)\n",
    "\n",
    "    # Merge assignment data with assignment relation data\n",
    "    ad_ar = df_assignment_rel.merge(df_assignment, how='left', left_on='in_unit_assignment_log_id', right_on='assignment_log_id')\n",
    "\n",
    "    # Calculate the total assignment count for each unit test assignment\n",
    "    assignment_total = ad_ar[['unit_test_assignment_log_id', 'in_unit_assignment_log_id']]\n",
    "    assignment_total = assignment_total.groupby('unit_test_assignment_log_id')['in_unit_assignment_log_id'].nunique().rename('Total_Assignment_Count')\n",
    "\n",
    "    # Calculate the count of unfinished in-unit assignments for each unit test assignment\n",
    "    notfinish = ad_ar[['unit_test_assignment_log_id', 'in_unit_assignment_log_id', 'notfinish']]\n",
    "    notfinish = notfinish.groupby('unit_test_assignment_log_id').sum()\n",
    "\n",
    "    # Merge the counts and calculate the percentage of unfinished in-unit assignments\n",
    "    notfinish = notfinish.merge(assignment_total, how=\"left\", left_index=True, right_index=True)\n",
    "    notfinish['notfinish_percent'] = notfinish['notfinish'] / notfinish['Total_Assignment_Count']\n",
    "    notfinish['notfinish_percent'] = notfinish['notfinish_percent'].round(4)\n",
    "\n",
    "    # Merge assignment data with df_final\n",
    "    df_assignment = df_assignment[['assignment_log_id', 'sequence_id']]\n",
    "    df_final = df_final.merge(df_assignment, left_on='unit_test_assignment_log_id', right_on='assignment_log_id', how='left')\n",
    "\n",
    "    # Merge the not_finished percent\n",
    "    df_final = df_final.merge(notfinish['notfinish_percent'], how='left', left_on='assignment_log_id', right_index=True)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df_final = df_final.drop(columns=['assignment_log_id'])\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3f60dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=merge_assignment_data(df_final, df_assignment, df_assignment_rel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0591a50f",
   "metadata": {},
   "source": [
    "## Sequence Details features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1147798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sequence_data(df_final, df_sequence):\n",
    "    df_sequence=df_sequence[['sequence_id', 'sequence_folder_path_level_1',\n",
    "       'sequence_folder_path_level_2','sequence_folder_path_level_3',\n",
    "       'sequence_folder_path_level_4']]\n",
    "    # Merge sequence data with training data\n",
    "    df_final = df_final.merge(df_sequence, on='sequence_id', how='left')\n",
    "\n",
    "    # Perform one-hot encoding on sequence folder path levels\n",
    "    one_hot = pd.get_dummies(df_final[['sequence_folder_path_level_1', 'sequence_folder_path_level_2', 'sequence_folder_path_level_3', 'sequence_folder_path_level_4']])\n",
    "\n",
    "    # Concatenate the original DataFrame with the one-hot encoded DataFrame\n",
    "    df_final = pd.concat([df_final, one_hot], axis=1)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df_final = df_final.drop(columns=['sequence_folder_path_level_1', 'sequence_folder_path_level_2', 'sequence_folder_path_level_3', 'sequence_folder_path_level_4'])\n",
    "    df_final = df_final.drop(columns=['sequence_id'])\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "755cd85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=merge_sequence_data(df_final, df_sequence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6334e54f",
   "metadata": {},
   "source": [
    "## Problem features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8771f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to clean the text\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and symbols\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51a49573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def merge_problem_data(df_final, df_problem):\n",
    "    # Merge the dataframes\n",
    "    df_final = df_final.merge(df_problem, on='problem_id', how='left')\n",
    "\n",
    "    # Split problem_skill_code into separate columns\n",
    "    df_final[['skill_code1', 'skill_code2', 'skill_code3', 'skill_code4']] = df_final.problem_skill_code.str.split('.', expand=True)\n",
    "\n",
    "    # Perform one-hot encoding on selected columns\n",
    "    one_hot = pd.get_dummies(df_final[['problem_type', 'problem_multipart_position', 'skill_code1', 'skill_code2', 'skill_code3', 'skill_code4']])\n",
    "\n",
    "    # Concatenate the original DataFrame with the one-hot encoded DataFrame\n",
    "    df_final = pd.concat([df_final, one_hot], axis=1)\n",
    "\n",
    "    # Split problem_text_bert_pca into separate columns\n",
    "\n",
    "    df_final['problem_text_bert_pca']=df_final['problem_text_bert_pca'].str.replace('[','').str.replace(']','')\n",
    "    df_final[['problem_text_bert_pca_' + str(i) for i in range(32)]]=df_final['problem_text_bert_pca'].str.split(',',expand=True)\n",
    "    df_final[['problem_text_bert_pca_' + str(i) for i in range(32)]]=df_final[['problem_text_bert_pca_' + str(i) for i in range(32)]].astype(float)\n",
    "    # Fill missing values and clean problem_skill_description\n",
    "    df_final.problem_skill_description = df_final.problem_skill_description.fillna('NA')\n",
    "    df_final.problem_skill_description = df_final.problem_skill_description.apply(clean_text)\n",
    "\n",
    "    # Load the BERT model\n",
    "    model = SentenceTransformer('bert-base-uncased')\n",
    "\n",
    "    # Encode the text data using BERT\n",
    "    embeddings_skill = model.encode(df_final.problem_skill_description.tolist())\n",
    "\n",
    "    # Apply dimensionality reduction using PCA to reduce the embeddings to 32 dimensions\n",
    "    pca = PCA(n_components=32)\n",
    "    reduced_embeddings_skill = pca.fit_transform(embeddings_skill)\n",
    "\n",
    "    # Scale the reduced embeddings using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaled_embeddings_skill = scaler.fit_transform(reduced_embeddings_skill)\n",
    "\n",
    "    # Create a DataFrame from scaled_embeddings_skill[:, :32]\n",
    "    embeddings_df = pd.DataFrame(scaled_embeddings_skill[:, :32])\n",
    "\n",
    "    # Assign the DataFrame to desired columns in df_problem\n",
    "    df_final[[f\"problem_skill_description{i}\" for i in range(32)]] = embeddings_df\n",
    "\n",
    "    # Perform frequency encoding on problem_multipart_id\n",
    "    frequency_encoding = df_final['problem_multipart_id'].value_counts()\n",
    "\n",
    "    # Create a dictionary to map the multipart ID to its frequency\n",
    "    frequency_map = frequency_encoding.to_dict()\n",
    "\n",
    "    # Replace the multipart ID column with its corresponding frequency values\n",
    "    df_final['Multipart_ID_Frequency'] = df_final['problem_multipart_id'].map(frequency_map)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df_final = df_final.drop(columns=['problem_multipart_id', 'problem_multipart_position', 'problem_type', 'problem_skill_code', 'problem_skill_description', 'problem_text_bert_pca', 'skill_code1', 'skill_code2', 'skill_code3', 'skill_code4'])\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b72d1827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1019424/3711443056.py:21: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_final['problem_text_bert_pca']=df_final['problem_text_bert_pca'].str.replace('[','').str.replace(']','')\n",
      "No sentence-transformers model found with name /home/aswani/.cache/torch/sentence_transformers/bert-base-uncased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /home/aswani/.cache/torch/sentence_transformers/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "df_final=merge_problem_data(df_final, df_problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde1bcd3",
   "metadata": {},
   "source": [
    "## Training and evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667854aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_train_data(df_final, df_total,df_eval):\n",
    "    # Filter rows with missing 'score' values\n",
    "    df_eval_final = df_final[df_final['score'].isna()]\n",
    "\n",
    "    # Merge with df_eval to get relevant columns\n",
    "    df_eval_final = df_eval_final.merge(df_eval[['id', 'assignment_log_id', 'problem_id']],\n",
    "                                        left_on=['unit_test_assignment_log_id', 'problem_id'],\n",
    "                                        right_on=['assignment_log_id', 'problem_id'])\n",
    "\n",
    "    # Merge with df_total to get 'score' values\n",
    "    df_eval_final = df_eval_final.merge(df_total[['assignment_log_id', 'problem_id', 'score']],\n",
    "                                        left_on=['unit_test_assignment_log_id', 'problem_id'],\n",
    "                                        right_on=['assignment_log_id', 'problem_id'])\n",
    "\n",
    "\n",
    "    # Filter rows with non-missing 'score' values\n",
    "    df_training = df_final.dropna(subset=['score'])\n",
    "\n",
    "    # Drop irrelevant columns\n",
    "    df_training = df_training.drop(columns=['unit_test_assignment_log_id', 'problem_id'])\n",
    "\n",
    "    # Fill missing values with -1\n",
    "    df_training = df_training.fillna(-1)\n",
    "\n",
    "    # Drop irrelevant columns from df_eval\n",
    "    df_eval_final = df_eval_final.drop(columns=['unit_test_assignment_log_id', 'problem_id'])\n",
    "\n",
    "    # Fill missing values with -1\n",
    "    df_eval_final = df_eval_final.fillna(-1)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df_eval_final = df_eval_final.drop(columns=['assignment_log_id_x', 'assignment_log_id_y', 'score_x'])\n",
    "\n",
    "    # Rename column 'score_y' to 'score'\n",
    "    df_eval_final = df_eval_final.rename(columns={'score_y': 'score'})\n",
    "\n",
    "    # Drop column 'id'\n",
    "    df_eval_final = df_eval_final.drop(columns=['id'])\n",
    "\n",
    "    return df_eval_final, df_training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b6bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval, df_training=get_eval_train_data(df_final, df_total,df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3a933948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124455, 404)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "83af4bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452439, 404)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccf7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save files\n",
    "pd.to_pickle('./saved_files/train_data.csv')\n",
    "pd.to_pickle('./saved_files/eval_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
